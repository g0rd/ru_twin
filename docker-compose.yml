version: '3.8'

services:
  # Local LLM server (Ollama)
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    deploy:
      resources:
        limits:
          memory: 8git branch -M mainG
    restart: unless-stopped

  # Database (Postgres)
  postgres:
    image: postgres:15
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_DB: ${DB_NAME}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped

  # Vector database (Chroma)
  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    volumes:
      - chroma_data:/chroma/chroma
    ports:
      - "8000:8000"
    restart: unless-stopped

  # Object storage (MinIO, S3 compatible)
  minio:
    image: minio/minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY}
    restart: unless-stopped

  # Redis for caching
  redis:
    image: redis:7
    container_name: redis
    ports:
      - "6379:6379"
    restart: unless-stopped

  # Search engine (optional, for web search)
  searxng:
    image: searxng/searxng
    ports:
      - "8080:8080"
    volumes:
      - searxng_data:/etc/searxng
    restart: unless-stopped

  # CrewAI application
  crewai:
    build: ./
    container_name: ru_twin_app
    depends_on:
      - postgres
      - ollama
      - chroma
      - minio
      - redis
      - searxng
    env_file: .env
    environment:
      DB_CONNECTION_STRING: postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
      VECTOR_DB_HOST: chroma
      MINIO_HOST: minio
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
      REDIS_URL: redis://redis:6379/0
      SEARXNG_HOST: searxng
      OLLAMA_HOST: ollama
    volumes:
      - ./config:/app/config
      - ./data:/app/data
    ports:
      - "3000:3000"
    restart: unless-stopped

  shopify_mcp:
    image: node:20
    container_name: shopify_mcp
    working_dir: /app
    command: npx -y @shopify/dev-mcp@latest
    ports:
      - "5005:5005"  # Expose the MCP server port (adjust if needed)
    volumes:
      - ./shopify_mcp_data:/app
    restart: unless-stopped

volumes:
  postgres_data:
  chroma_data:
  minio_data:
  ollama_models:
  searxng_data: 


#   version: '3.8'

# services:
#   # Main application service
#   app:
#     build:
#       context: .
#       dockerfile: Dockerfile
#     container_name: ru_twin_app
#     restart: unless-stopped
#     volumes:
#       - ./src:/app/src
#       - ./knowledge:/app/knowledge
#     env_file:
#       - .env
#     ports:
#       - "8000:8000"  # FastAPI server
#     depends_on:
#       - phoenix
#     environment:
#       - OTEL_EXPORTER_OTLP_ENDPOINT=http://phoenix:4317
#       - OTEL_EXPORTER_OTLP_PROTOCOL=grpc
#       - OTEL_SERVICE_NAME=ru_twin
#     networks:
#       - ru_twin_network

#   # Arize Phoenix observability service
#   phoenix:
#     image: arizepublic/phoenix:latest
#     container_name: ru_twin_phoenix
#     restart: unless-stopped
#     ports:
#       - "6006:6006"  # Phoenix UI
#       - "4317:4317"  # OTLP gRPC endpoint
#     volumes:
#       - ./phoenix-data:/phoenix/data  # Persist data
#     environment:
#       - PHOENIX_PORT=6006
#       - PHOENIX_HOST=0.0.0.0
#       - PHOENIX_DATA_PATH=/phoenix/data
#     networks:
#       - ru_twin_network
#     healthcheck:
#       test: ["CMD", "curl", "-f", "http://localhost:6006/health"]
#       interval: 30s
#       timeout: 10s
#       retries: 3
#       start_period: 10s

# networks:
#   ru_twin_network:
#     driver: bridge

# volumes:
#   phoenix-data:
#     driver: local
